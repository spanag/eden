{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Local field potential\n",
    "\n",
    "In this example, we show how one can sample the Local Field Potential around a neuron, by extracting the necessary data from the simulation and applying the LFP caclulations for the desired sample points.\n",
    "\n",
    "If one adds a population of neurons, does the relevant changes and focuses the sample points closer, the same methods can also yield the multi-unit activity (mind the simulation timestep though)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "First of all, let's install the required software, if on certain platforms like Colab that run the bare notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; from pathlib import Path\n",
    "if 'COLAB_BACKEND_VERSION' in os.environ:\n",
    "  !TMP=$(mktemp -d); git clone https://eden-simulator.org/repo --depth 1 -b development \"$TMP\"; cp -r \"$TMP/.\" .; rm -rf \"$TMP\"\n",
    "  exec(Path('.binder/install_livenb.py').read_text())\n",
    "if 'DEEPNOTE_PROJECT_ID' in os.environ: exec(Path('../.binder/install_livenb.py').read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the model\n",
    "Let's see what the LFP looks like for the L5 pyramidal cell from [Mainen et al. 1995]( https://github.com/OpenSourceBrain/MainenEtAl_PyramidalCell ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the zip file with the model\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve('https://codeload.github.com/OpenSourceBrain/MainenEtAl_PyramidalCell/zip/refs/heads/master', 'Mainen95.zip')\n",
    "# and unpack it\n",
    "from zipfile import ZipFile\n",
    "with ZipFile('Mainen95.zip', 'r') as zipp: zipp.extractall()\n",
    "# Check which files are present now\n",
    "# from os import listdir; listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the folder (through the GUI or os.listdir) and locate the NeuroMLv2 folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nml_dir = 'MainenEtAl_PyramidalCell-master/neuroConstruct/generatedNeuroML2/'\n",
    "# listdir(nml_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and run the simulation\n",
    "\n",
    "We'll run the existing setup with a lone neuron and a pulse clamp on it, but we'll make a whole new simulation file to capture all points of the neuron.\n",
    "\n",
    "First analyse the cell to extract the compartments this neurons contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_filename = nml_dir+\"MainenEtAl_PyramidalCell.net.nml\"\n",
    "celltype_name = 'MainenNeuroML'\n",
    "import eden_simulator\n",
    "cells_info = eden_simulator.experimental.explain_cell(net_filename)\n",
    "cell_info = cells_info[celltype_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_mid_seg = cell_info['comp_midpoint_segment']\n",
    "comp_mid_fra = cell_info['comp_midpoint_fractionAlong']\n",
    "n_comps = len(comp_mid_seg) # Number of actual compartments in this cell, may be retrieved from most cell_info arrays\n",
    "print(f'Compartments: {n_comps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then generate the new simulation file with its traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'network_MainenEtAl_PyramidalCell';\n",
    "population_name = 'NeuroMLBased'; N_cells = 1\n",
    "# Set a new routine for making the <Simulation> file with new recording options\n",
    "def NmlSimParms(network_name, run_time, run_timestep=25e-6, sampling_period=1e-3,\n",
    "            rec_lines='', href='file://results.gen.txt'):\n",
    "    return f'''\n",
    "        <Simulation id=\"sim1\" length=\"{run_time}s\" step=\"{run_timestep}s\" target=\"{network_name}\">\n",
    "            <EdenOutputFile id=\"first\" href=\"{href}\" format=\"ascii_v0\" sampling_interval=\"{sampling_period} s\">\n",
    "            '''+'\\n\\t        '.join(rec_lines)+'''\n",
    "            </EdenOutputFile>\n",
    "        </Simulation>\n",
    "        <Target component=\"sim1\"/>'''\n",
    "\n",
    "# Make the traces to record each compartment, and save the file\n",
    "traces = [f\"{population_name}[{neu}]/{celltype_name}/{comp_mid_seg[i]}{('%.9f'%comp_mid_fra[i])[1:]}/v\"\n",
    "    for neu in range(N_cells) for i in range(len(comp_mid_seg))]\n",
    "rec_lines = [f'<OutputColumn id=\"v_{i}\" quantity=\"{x}\"  output_units=\"mV\"/>' for i,x in enumerate(traces) ]\n",
    "print(f\"recording {len(rec_lines)} waveforms this time !\")\n",
    "sim_filename = nml_dir+\"/SimLFP.xml\"\n",
    "with open(sim_filename, \"w\") as f:   \n",
    "    f.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<Lems>\\n<include file=\"MainenEtAl_PyramidalCell.net.nml\"/>\\n')\n",
    "    f.write(NmlSimParms(network_name, run_time=0.06, run_timestep=10e-6, sampling_period=0.1e-3, href='moresults.gen.txt', rec_lines=rec_lines))\n",
    "    f.write('\\n</Lems>\\n')\n",
    "# !cat $nml_dir/SimMore.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time moresults = eden_simulator.runEden(sim_filename)\n",
    "timevec = moresults['t']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'll be doing physics with the simulation's results so that we can calculate the LFP, let's convert the $V_m$ data to a physical `Quantity` with the help of the `pint` [Python package]( https://pint.readthedocs.io/en/stable/user/defining-quantities.html ) for unit math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pint.registry import Quantity as Q\n",
    "neuron_membrane_voltage = np.array([moresults[x] for i,x in enumerate(traces)])\n",
    "neuron_membrane_voltage = Q(neuron_membrane_voltage,'mV')\n",
    "print(\"%d points in space, sampled over %d points in time.\" % neuron_membrane_voltage.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a raster of $V_m$ per compartment: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "im = plt.imshow(neuron_membrane_voltage.m_as('mV'),\n",
    "    extent=[ timevec[0], timevec[-1], n_comps, 0 ],\n",
    "    aspect='auto', interpolation='none', cmap =\"viridis\")\n",
    "cbar = plt.colorbar(im); cbar.set_label('Voltage (mV)')\n",
    "plt.clim((-50, +50)); plt.ylabel('Compartment #'); plt.xlabel('Time (sec)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an animation of said $V_m$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eden_simulator.display.animation import subsample_trajectories\n",
    "samples_vm, anim_axis_vm, sampled_time_vm, (sampled_voltage,) = subsample_trajectories(\n",
    "    timevec, [neuron_membrane_voltage.m_as('mV').T], animation_speed=0.0048, animation_frames_per_second=24)\n",
    "\n",
    "import k3d; from eden_simulator.display.spatial.k3d import Plot, plot_neuron\n",
    "Vm_plot = plot = Plot()\n",
    "plot += plot_neuron(cell_info, sampled_voltage, time_axis_sec=anim_axis_vm,\n",
    "                             color_range=[-70, -20],color_map='rainbow');\n",
    "plot.camera = plot.get_auto_camera(pitch=30, yaw=10)[:6]+[0,1,0] # set 'y' to up ! vecs are pos, tgt, up\n",
    "k3d_label_dict = { str(real_time): f't = {sim_time*1000:.1f} ~ ms' for (real_time, sim_time) in zip(anim_axis_vm, sampled_time_vm)  }\n",
    "plt_label = k3d.text2d(k3d_label_dict, (0.,0.)); plot += plt_label # add 2d elements AFTER setting auto camera\n",
    "plot.show_html()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/latex"
   },
   "source": [
    "% 8 [-219.63692808160695, 64.08110468381233, 457.33175174354596, -190.6857026308152, 68.20081299573673, -18.981236386344637, -0.9999541463520134, 0.008028139341647584, -0.005220552855270645]\n",
    "\\begin{center}\\sphinxincludegraphics[width=0.9\\textwidth]{{_static/example_lfp_3d_vm}.png}\\end{center}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-process simulation data to get $I_m$\n",
    "\n",
    "We have recorded $V_m$ all over the cell and we'll use it (along with the cell's properties) to obtain the resulting LFP.\n",
    "\n",
    "The usual assumptions apply for this example: The extracellular medium is uniform, highly conductive, isotropic and unobstructed until far away.  If you need a more sophisticated model, apply the relevant adjustments to the following.  (Perhaps a separate simulation process just for the LFP is called for, see the other articles TBD on \"Pipelines\" generally.)\n",
    "<!-- LATER pipelines -->\n",
    "\n",
    "If storing all voltage traces is becoming a burden, one can calculate the coupling matrix as they prefer and add up the numbers using virtual \"gap junctions\".  (The virtual gap junction method can be shown in a TBA article).  \n",
    "For really large numbers of current sources, it might become more efficient to stream values with a pipeline to the Barnes-Hut algorithm or the fast multipole method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we'll be looking at the LFP, hence we need $I_m$ .  Instead of adding up the current from each mechanism, we can estimate it through $dV_m/dt$. To reduce sampling artifacts, we could convolve with a [derivative of Gaussian]( https://inst.eecs.berkeley.edu/~cs194-26/fa17/Lectures/ConvEdgesTemplate.pdf ) in the place of `np.diff` but it's not a concern here.\n",
    "\n",
    "The dynamics of membrane voltage per compartment, are as follows: \n",
    "$$C\\dot{V}_m = I_{axial} + I_m + I_{injected}$$ \n",
    "Therefore we should subtract the current from adjacent compartments and the current from direct injection through the membrane, to isolate the trans-membrane current.\n",
    "\n",
    "*Note:* Although direct injections cross the membrane (topologically), they don't count towards the LFP because charge travels from inside a body to inside another; thus the extracellular environment is not affected.  \n",
    "Examples of direct injections are current clamps, as well as gap junctions between cells.\n",
    "\n",
    "Whether a stimulus from our rig should count as trans-membrane current or direct injection is ultimately up to the modeller's intention; due caution is advised. (eg. is a \"virtual synapse\" stimulus imposed by a clamp, or a simulated synapse?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# J = dQ/dt = C * dV/dt\n",
    "rec_dt = Q(np.diff(timevec)[0],'sec')\n",
    "comp_capa = Q(cell_info['comp_capacitance'],'pF')\n",
    "\n",
    "neuron_comp_flux = comp_capa[:,None]*(np.diff(neuron_membrane_voltage)/rec_dt)\n",
    "neuron_comp_flux.ito('pA') # Convert to specific units this way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the total current flow for each compartment.\n",
    "\n",
    "The simulator provides absolute numbers for unevenly sized compartments, the *density* over the membrane is perhaps more informative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(18,5))\n",
    "im = axs[0].imshow(neuron_comp_flux.m_as('pA'),\n",
    "    extent=[ moresults['t'][0], timevec[-1], n_comps, 0 ],\n",
    "    aspect='auto', interpolation='none', cmap =\"bwr_r\");\n",
    "cbar = plt.colorbar(im); cbar.set_label('pA')\n",
    "im.set_clim((-30, +30)); axs[0].set_ylabel('Compartment #'); axs[0].set_xlabel('Time (sec)');\n",
    "axs[0].set_title(\"Comp. current\")\n",
    "# Now, get the density\n",
    "comp_area = Q(cell_info['comp_area'], 'um*um')\n",
    "neuron_comp_flux_density = neuron_comp_flux/comp_area[:,None]\n",
    "im = axs[1].imshow(neuron_comp_flux_density.m_as('pA/um**2'),\n",
    "    extent=[ moresults['t'][0], timevec[-1], n_comps, 0 ],\n",
    "    aspect='auto', interpolation='none', cmap =\"bwr_r\");\n",
    "cbar = plt.colorbar(im); cbar.set_label('pA/Œºm¬≤')\n",
    "im.set_clim((-.4, +.4)); axs[1].set_ylabel('Compartment #'); axs[1].set_xlabel('Time (sec)');\n",
    "axs[1].set_title(\"Current density\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the total current flux in/out of the compartment, where `+` is for current `in` and `-` for current `out` of the cell (of course, the reverse applies for electrons and negative ions).  \n",
    "We use the `bwr_r` colormap where blue is for positive flow `in`ward, because this flow will cause an opposite, *negative* potential outside the cell - which we'll get to see in the calculated LFP.\n",
    "\n",
    "To correct the numbers, let's calculate and subtract the \"axial\" current flowing between compartments, based on the known electrical conductance between them.  \n",
    "In this example, axial current is far far less than true trans-membrane current so there's no obvious difference, we should do it nonetheless.\n",
    "\n",
    "### Correcting for axial current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get the axial resistance matrix: Ia = G*V. It follows the tree structure\n",
    "comp_ga = cell_info['comp_conductance_to_parent']\n",
    "iii = []; jjj = []; vvv = [] # Construct the lists (i,j,v)\n",
    "for i,p in enumerate(cell_info['comp_parent']):\n",
    "    g = comp_ga[i]\n",
    "    if p >= 0:\n",
    "        iii += [ i, p, i, p] # add 4 sparse elms in one go\n",
    "        jjj += [ p, i, i, p]\n",
    "        vvv += [+g,+g,-g,-g] # same as:\n",
    "        # axial_conductance_matrix[i,p] += g\n",
    "        # axial_conductance_matrix[p,i] += g\n",
    "        # axial_conductance_matrix[i,i] -= g\n",
    "        # axial_conductance_matrix[p,p] -= g\n",
    "\n",
    "import scipy\n",
    "G = scipy.sparse.coo_matrix((vvv,(iii,jjj))).tocsr() # needs csr for some reason'\n",
    "G = Q(G,'nS')\n",
    "\n",
    "# One would think Ia = G*V directly, but the discretisation of the neuron \n",
    "# leads to rough ŒîV gradient between compartments in practice (plot Vm of the stylized axon, last 125 comps, around sample 100 to see). \n",
    "# -> hence Ia would come out extremely rough and inaccurate.\n",
    "# In its place we will use Bwd Euler to estimate the currents (neglecting ion channel conductance tbh):\n",
    "# Ia = C*dV/dt = G*V => Ia*dt = Vnext-Vnow = dt*inv(C)*G*Vnext, Vnext = inv(I-dt*inv(C)*G)*Vnow.\n",
    "# Then, make the dimensionless \"dynamics matrix\" that will give us Vnext from vnow.\n",
    "\n",
    "I = scipy.sparse.eye(n_comps); invC = (scipy.sparse.diags(1/comp_capa.m))\n",
    "# neither pint nor quantities can do matmul :c\n",
    "dynamics_matrix = I - (\n",
    "        (rec_dt.units*G.units/comp_capa.units) * (rec_dt.m*invC @ G.m)\n",
    "    ).to('1').m # cast to proper quantity, not eg. meters/km\n",
    "\n",
    "\n",
    "def get_true_membrane_current(comp_flux, membrane_voltage, G, time=0): \n",
    "    # instead of direct: axial_current = (G.m @ membrane_voltage.m)*G.units*membrane_voltage.units\n",
    "    vNext_axial = Q(scipy.sparse.linalg.spsolve(dynamics_matrix, membrane_voltage.m_as('mV')),'mV')\n",
    "    axial_current = (vNext_axial -  membrane_voltage) * comp_capa[:,None] / rec_dt\n",
    "    return (comp_flux - axial_current)\n",
    "neuron_membrane_current = get_true_membrane_current(neuron_comp_flux, neuron_membrane_voltage[:,:-1], G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: because direct currents such as patch clamps come from insulated wires, they *don't* affect the observed LFP, hence it is well possible that a 'monopole' appears during such stimulation!\n",
    "\n",
    "Kirchhoff's law still stands: $$I_{membrane} = -(I_{capacitive} + I_{injected})$$\n",
    "it's just that we can't measure the right hand side through extracellular space.\n",
    "\n",
    "If you're interested, repeat the graph from above to plot the difference between `neuron_comp_flux` and `neuron_membrane_current`, in absolute and per area terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intentionally left blank "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that come compartments are much more affected by axial current than others.  \n",
    "Generally, the less area they have, and the tighter they are coupled to adjacent compartments, the more affected they are by axial current. (Cytoplasmic resistivity `Ra` and membrane spec. capacitance `Cm` can also matter when non-uniform.)  \n",
    "Feel free to plot `comp_ga` and `comp_capa` (and the ratio thereof `1/RC`) to see which these may be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "Let's see then how the trans-membrane current evolves on the neuron.  We'll use the same Red-White-Blue colormap we'll display the LFP with, in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the anim_axis because Im has 1 time point less than Vm, due to np.diff\n",
    "samples_im, anim_axis_im, sampled_time_im, [sampled_current_density] = subsample_trajectories(\n",
    "    timevec[:-1], [(neuron_membrane_current / comp_area[:,None]).m_as('pA/um**2').T], animation_speed=0.0048, animation_frames_per_second=24)\n",
    "\n",
    "Im_plot = plot = Plot()\n",
    "plot += plot_neuron(cell_info, sampled_current_density, time_axis_sec=anim_axis_im,\n",
    "                             color_range=[-.2, +.2],color_map='bwr');\n",
    "plot.camera = plot.get_auto_camera(pitch=30, yaw=10)[:6]+[0,1,0] # set 'y' to up ! vecs are pos, tgt, up\n",
    "plot.show_html()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/latex"
   },
   "source": [
    "% 4.61 [-219.63692808160695, 64.08110468381233, 457.33175174354596, -190.6857026308152, 68.20081299573673, -18.981236386344637, -0.9999541463520134, 0.008028139341647584, -0.005220552855270645]\n",
    "\\begin{center}\\sphinxincludegraphics[width=0.9\\textwidth]{{_static/example_lfp_3d_current}.png}\\end{center}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-process $I_m$ to get the LFP\n",
    "\n",
    "The other half of calculating the LFP is how much each point outside the cell is being affected by the current flow on each part of the neuron (that is, mostly by the closest compartments, but also slightly from the more distant ones).\n",
    "\n",
    "Just for illustration, we'll use one element per compartment. It would be even better if each NeuroML `<segment>` is applied separately, if it's not too much for the computer.  \n",
    "Alternatively, the [LFPykit]( https://github.com/LFPy/LFPykit ) could also be used to calculate the coupling matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracell_conductivity = Q(.3, 'S/m')\n",
    "\n",
    "source_points = cell_info['comp_midpoint'][:]\n",
    "x_space = np.linspace(-360, 000, 10); y_space = np.linspace(-180, 600, 30); z_space = [-30]\n",
    "x, y, z = np.meshgrid(x_space, y_space, z_space, indexing='ij')\n",
    "sampling_points = np.stack((x,y,z),axis=-1).reshape((-1,3))\n",
    "# print(\"Sampling points:\", sampling_points)\n",
    "\n",
    "# Vectorize calculation of pairwise distance matrix https://jaykmody.com/blog/distance-matrices-with-numpy/\n",
    "distmat =  source_points @ sampling_points.T#np.sum(,axis=-1)\n",
    "distmat = np.sum(sampling_points**2,axis=-1) - 2*distmat + np.sum(source_points**2,axis=-1)[:,None]\n",
    "distmat = np.sqrt(distmat)\n",
    "distmat = Q(distmat, 'um')\n",
    "\n",
    "# LATER: Exclude current from points inside the cell, thereby avoiding singularities as a bonus.\n",
    "coupling = (1e-0 / (4*np.pi*extracell_conductivity*distmat)).to('uV/pA')\n",
    "\n",
    "print('Coupling is calculated for %d current sources times %d sampling points.' % coupling.shape)\n",
    "def get_lfp(membrane_current): return ((coupling.m.T @ -membrane_current.m)*coupling.units*membrane_current.units).to('uV')\n",
    "# get_lfp(neuron_membrane_current[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's show the membrane voltage and the observed LFP together in one animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animate the lfp, similar to label but with a vector instead of a string\n",
    "lfp_uvolt = get_lfp(neuron_membrane_current).m_as('uV').T\n",
    "k3d_lfp_dict = { str(real_time): x.astype(np.float32) \n",
    "                for (real_time, x) in zip(anim_axis_vm, lfp_uvolt[samples_im])  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_plot = plot = Plot()\n",
    "\n",
    "lfp_scale_range = [-2, 2] #other options to see transitions vs. absolute range: [-.2, .2], [-.5, +.5] ... \n",
    "plt_points = k3d.points(positions=sampling_points.astype(np.float32),attribute=k3d_lfp_dict,\n",
    "        color_range=lfp_scale_range,point_size=10,color_map=k3d.matplotlib_color_maps.Bwr); plot += plt_points\n",
    "\n",
    "plot.camera = plot.get_auto_camera(pitch=30, yaw=10)[:6]+[0,1,0] # set 'y' to up ! vecs are pos, tgt, up\n",
    "plt_mesh = plot_neuron(cell_info, sampled_voltage, time_axis_sec=anim_axis_vm,\n",
    "                    color_range=[-70, -20],color_map='rainbow', compress_cells=False);\n",
    "plot += plt_mesh\n",
    "plt_label = k3d.text2d(k3d_label_dict, (0.,0.)); plot += plt_label # add 2d elements AFTER setting auto camera\n",
    "plot.show_html()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/latex"
   },
   "source": [
    "% LATER 6.91 [-170.37880542608738, 96.0253956924614, 457.3453271173898, -180.01893156667765, 95.79917182371453, -19.76705472116063, -0.9971358760109222, -0.0036016041927074698, 0.07554517336759459] [-219.63692808160695, 64.08110468381233, 457.33175174354596, -190.6857026308152, 68.20081299573673, -18.981236386344637, -0.9999541463520134, 0.008028139341647584, -0.005220552855270645]\n",
    "\\begin{center}\\sphinxincludegraphics[width=0.9\\textwidth]{{_static/example_lfp_3d_full}.png}\\end{center}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dots around the neuron are the sampling points for the LFP, they don't necessarily have to be a regular grid (but it's easier to understand this way).  \n",
    "They are coloured with red ‚ù§Ô∏è for positive potential, blue üíô for negative, and white ü§ç for zero.\n",
    "\n",
    "Observe that the LFP goes negative (blue) near where the cell depolarizes, and positive (red) where the cell repolarizes. (Also depnding on the activity of the more distant parts, of course.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More ideas\n",
    "\n",
    "The enterprising reader may find more nuances and improved ways of calculating the LFP in the work of, among others, Einevoll and his lab. \n",
    "\n",
    "For best results, consider using non-uniform sampling grids, centered around where the potential changes most sharply and where the (both stimulation and recording) electrodes are located."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "Now as the last thing, we'll fetch a screenshot to use in the documentation's [example gallery]( https://eden-simulator.org/gallery.html ).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "plot = LFP_plot\n",
    "plot.grid_visible = False\n",
    "plot.screenshot_scale = 1\n",
    "plot.axes_helper = 0\n",
    "plot.colorbar_object_id = 0 # Disabling colorLegend programmatically\n",
    "plt_points.color_range = [-1, +1]\n",
    "plt_points.point_size = 15\n",
    "plt_label.visible=False\n",
    "plot -= plt_label\n",
    "data_timestep = np.diff(timevec)[0] # assuming fixed timestep\n",
    "traj_samples_per_frame = round((0.0048/24)/data_timestep)\n",
    "# print(len(list(k3d_anim_dict.keys())))\n",
    "frameis = [x for x in range(int(0.031/(data_timestep*traj_samples_per_frame)),int(0.031/(data_timestep*traj_samples_per_frame))+1,traj_samples_per_frame)]\n",
    "frames = []\n",
    "# for frame,sample in enumerate(sample_for_frame):print(sample_for_frame)\n",
    "# print(framets)\n",
    "\n",
    "# print(plt_mesh.attribute)\n",
    "# raise\n",
    "import time\n",
    "try:\n",
    "    from k3d.headless import k3d_remote, get_headless_driver\n",
    "    headless = k3d_remote(plot, get_headless_driver(), width=500, height=300)\n",
    "#     # plot.camera = lotp.get_auto_camera(pitch=30, yaw=10)[:6]+[0,1,0] # set 'y' to up !  LATER zoom a bit also; vecs are pos, tgt, up\n",
    "    plot.camera = [0, 0, +200, 0,0,0, -1,0,0]\n",
    "    headless.sync(hold_until_refreshed=True)\n",
    "    headless.camera_reset(.49)\n",
    "    # Set each attribute because does headless not like dicts ...\n",
    "    for frame,i in enumerate(frameis):\n",
    "        # need to clear before reassigning...\n",
    "        attt = list(plt_mesh.attribute.items())[i][1]\n",
    "        for x in plt_points,plt_mesh: x.attribute = {k:[] for k,v in x.attribute.items()}\n",
    "        \n",
    "        plt_mesh.attribute = attt\n",
    "        plt_points.attribute = list(k3d_lfp_dict.items())[i][1]\n",
    "\n",
    "        headless.sync()\n",
    "        time_start = time.time()\n",
    "        screenhot = headless.get_screenshot()\n",
    "        time_end = time.time()\n",
    "        # print(f\"{time_end - time_start} sec\")\n",
    "        frames.append(screenhot)\n",
    "finally:\n",
    "    headless.close()\n",
    "import IPython\n",
    "IPython.display.Image(data=frames[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL\n",
    "import io\n",
    "\n",
    "# Stage 1: Crop\n",
    "frame_data = [ Image.open(io.BytesIO(x)) for x in frames]\n",
    "frame_data = [ x.crop((int(0.3*x.size[0]), int(0.2*x.size[1]), int((1-.01)*x.size[0]), int((1-0.1)*x.size[1]))) for x in frame_data ]\n",
    "# frame_data = [ x.crop((int(0.25*x.size[0]), int(0.25*x.size[1]), x.size[0], x.size[1])) for x in frame_data ]\n",
    "\n",
    "# Stage 2: Resize\n",
    "for x in frame_data: x.thumbnail((240,200))\n",
    "    \n",
    "# Stage 3: Lossy - or not\n",
    "# frame_data = [x.convert('P',palette=Image.Palette.ADAPTIVE,dither=Image.Dither.NONE,colors=256) for x in frame_data]\n",
    "# to apng, or gif\n",
    "outbuf = io.BytesIO()\n",
    "frame_data[0].save(outbuf, format='gif', save_all=True, append_images=frame_data[1:], duration=100, loop=0)\n",
    "print('GIF size:',len(outbuf.getvalue()))\n",
    "\n",
    "# to alpha channel out - how is this not compressed already\n",
    "im = Image.open(outbuf)\n",
    "# https://github.com/python-pillow/Pillow/issues/3292#issuecomment-410837926\n",
    "newframes = [x.copy().convert('RGB') for x in PIL.ImageSequence.Iterator(im)]\n",
    "\n",
    "aabuf = io.BytesIO()\n",
    "newframes[0].save(aabuf, format='png', save_all=True, append_images=newframes[1:], duration=100, loop=0)\n",
    "print(len(aabuf.getvalue()))\n",
    "\n",
    "# to lossless recompression\n",
    "import oxipng\n",
    "oxipng_opts = {'level':6}\n",
    "aa = oxipng.optimize_from_memory(aabuf.getvalue(), **oxipng_opts)\n",
    "print('Optimized PNG size:',len(aa))\n",
    "\n",
    "# display(IPython.display.Image(data=outbuf.getvalue()))\n",
    "# display(IPython.display.Image(data=aabuf.getvalue()))\n",
    "display(IPython.display.Image(data=aa))\n",
    "\n",
    "# IPython refuses to nbconvert gif files, and apng is not as efficient, we'll have to get creative ...\n",
    "# Accept having a png file for now? nah it's twice as big as the gif after gif compression.\n",
    "# and save the file under an explicit name bc nbsphinx is misbehaving\n",
    "with open('_static/thumb_exa_lfp.png','wb') as f: f.write(aa)\n",
    "# with open('_static/thumb_tut_net.gif','wb') as f: f.write(outbuf.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "And minimize plots for publishing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "from eden_simulator.display.spatial.k3d import MinimizePlot\n",
    "for x in [Vm_plot, Im_plot, LFP_plot]: MinimizePlot(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
