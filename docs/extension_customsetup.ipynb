{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension: Custom per-element variability\n",
    "\n",
    "As we saw in the [NeuroML introduction tutorial]( intro_neuroml.ipynb ), models comprise a `<network>` of neuron *populations* connected by synapse *projections*, and some experimental rig around them to interact with through.\n",
    "\n",
    "In practice, a problem that emerges often when modelling is that NeuroML defines populations of *identical* neurons, and projections with identical components.  The state of each instance may of course vary through the simulation, but the parameters and initial state are the same for all instances of a cell (or synapse or input type, or generally LEMS component instance).\n",
    "\n",
    "However, this is not always sufficient to make a realistic model, as neurons can show considerable physiological variability in nature.  And even when neurons and synapses are of the same type, a small amount of variability is desired in models to make them more [robust]( https://doi.org/10.1371/journal.pone.0080694 ).\n",
    "\n",
    "For these reasons, modellers often require that each neuron or synapse may have its parameters *slightly different* than the rest; and what's more, the *kind* of variability, or anatomy-informed) is often unique to that model part, or at least project or research laboratory.  Typical examples of variability models include mathematical formulae, anatomical data or random sampling of statistical distributions.  What's then needed is a way to apply *any* kind of variability to the model directly.  And in the general case, this includes assigning an *explicit* set of values, one by one, to a collection of mechanisms.\n",
    "\n",
    "EDEN supports models with arbitrary per-instance variability, in a way that allows for any modelling pipeline by design.  It does this through the `<EdenCustomSetup>` extension, and a special *setup language* for supplying and designating the variability data.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Tip\n",
    "    \n",
    "This is a simulator-specific interim data format.  It may be replaced with equivalent NeuroML capabilities as they appear.\n",
    "</div>\n",
    "\n",
    "The first step in using custom variability is to add the tag `<EdenCustomSetup filename=\"<file name>\" />` inside the usual `<Simulation>` tag.\n",
    "\n",
    "The file under `file name` then, contains the customisation information as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `EdenCustomSetup` file specification\n",
    "\n",
    "The setup language is (to this point) essentially a sequence of `set` statements, which set the values of quantities (i.e.  `<Property>`s ) over a set of mechanisms.\n",
    "\n",
    "Note that these statements are considered in *strict order*: a `set` statement may supersede values assigned by a previous statement to the same mechanism!\n",
    "\n",
    "In order to specify a *collection* of mechanisms instead of just a single one, the LEMS path machinery is used in a kind of re-mixed form.  It is broken down into:\n",
    "\n",
    "* the part that locates an entity in the `<network>`, which in turn is broken down into:\n",
    "    * the \"collection\" of entities in the network, that is a neuron `<population>`, synaptic `<projection>`, or `<inputList>`,\n",
    "    * and the \"identifiers\" of entities within said collection.  A `set` statement may name multiple identifiers, to share the same quantity value or get each one value from a list of `multi`ple, as we'll see below.\n",
    "    * For spatially-detailed `<cell>` populations, there is also a list of different [*cell locations*]( intro_spatial.ipynb#Specifying-a-location-on-a-cell ) that comes after the list of cell identifiers.  The mechanisms in these locations may in turn take the same value, or different ones. \n",
    "* and the path *within* the entity that locates the quantity in terms of the sub-mechanism that it belongs to, and its identifier name within.\n",
    " \n",
    "For the extended set of LEMS paths that EDEN understands (and a hint as to how they may be appled here), refer to EDEN's [LEMS paths reference]( extension_paths.rst ).\n",
    "\n",
    "<!-- Tip: <StateVariable>s may also be set, the value applies if initialisation is not handled by any no `<OnStart>` clause in the `<ComponentType>` definition, (in which case the would have a value of `0`, for compatibility with jLEMS behaviour) plese don't leave unspecified though...?  LATER -->\n",
    "<!-- LATER also specify core quantities if needed, eg capacitance, densities ...  -->\n",
    "\n",
    "### General structure\n",
    "\n",
    "`<EdenCustomSetup>` files are written as human-readable text lines;  an equivalent binary format for higher data density is also planned.\n",
    "\n",
    "The contents of the file are arranged in *lines*; each line contains *tokens* separated with space and tab characters, and other \"white-space\" characters.\n",
    "\n",
    "The types of lines are as follows:\n",
    "\n",
    "* `set` statements, for:\n",
    "    * `cell` populations\n",
    "    * `synapse` projections\n",
    "    * `input` lists\n",
    "* `values` lines, which follow the `set` statements that specify `multi`ple values;\n",
    "* empty and \"comment\" lines to aid readability for humans.\n",
    "\n",
    "The structure of these lines is described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `set cell` statement\n",
    "\n",
    "A `set cell` statement line is a sequence of tokens as follows:\n",
    "\n",
    "```\n",
    "set cell <population> <cell list> <location list> <attribute> <value>\n",
    "```\n",
    "\n",
    "The tokens have the following meanings, in order:\n",
    "\n",
    "* `population`: The name of the neuron `<population>` whose cells' quantities are customised.\n",
    "* `cell list`: Either a comma-separated list of cell instance `id`'s in strictly ascending order, or `all` to designate the whole population.\n",
    "* `location list`: Can be either:\n",
    "    * a comma-separated list of [segment locators]( extension_paths.rst#lems-paths-for-cell-locations ) on cell;\n",
    "    * `all` to apply all over the cell;\n",
    "    * or the name of a [\"cable\"]( intro_spatial.ipynb#The-unbranched-section-directive ) segment group, to sample values along a track of sampling points.\n",
    "    \n",
    "    For point neurons, options are the equivalent `all` or `0` (the implicit singular \"segment\" `id`, as per [LEMS paths]( extension_paths.rst )).\n",
    "* `attribute`: The part of the [LEMS path]( extension_paths.rst ) *within* the neuron, that follows after `population[id]/segment/`\n",
    "* `value`: The single quantity value ,or `multi` to specify more, in the `values` lines that follow.\n",
    "    Examples for how `value`s look like:\n",
    "    \n",
    "    * `100 pA` to specify an amount of electrical current;\n",
    "    * `multi mV` to specify one or more voltage values, in one or more `values` lines that follow;\n",
    "    * `3.14159` to specify a dimensionless, pure number;\n",
    "    * `multi` to specify one or more dimensionless numbers, or [<𝚅𝚊𝚛𝚒𝚊𝚋𝚕𝚎𝚁𝚎𝚚𝚞𝚒𝚛𝚎𝚖𝚎𝚗t> paths]( #Setting-VariableRequirements ).\n",
    "\n",
    "If the `location list` is \"all\" and `multi`ple values are specified, one `values` line follows, with one value per cell instance in the `cell list`.\n",
    "\n",
    "If the `cell list` includes only one cell, the `location list` contains multiple segment locators and `multi`ple values are specified, one `values` line follows, with one value per segment locator in the `location list`.\n",
    "\n",
    "When both the `cell list` contains multiple cells and the `location list` contains multiple segment locators, there are different ways to specify multiplicity.  The `multi` value specifier has to be replaced by:\n",
    "\n",
    "* `multi_location`, in which case the same values are applied to all cells, and one `values` line follows with the value for each segment locator;\n",
    "* `multi_cell`, in which case the same value is applied to all segment locators per cell, and one `values` line follows with the value for each cell;\n",
    "* `multi_multi`, in which case a different value is applied to each cell on each segment locator. As many `values` lines as the number of mentioned cells follow, each line with the value for each segment locator on the listed cell.\n",
    "\n",
    "#### Cable mode\n",
    "\n",
    "When the location list is a \"cable\" `<segmentGroup>`, a special *cable interpolation mode* is engaged, wherein the mechanism value is sampled across the cable's extent for each compartment, based on a piecewise-linear function that's provided in the `values` lines that follow.  \n",
    "\n",
    "The `value` token must be `cable` or `cable_multi`.  At least two `values` lines follow:\n",
    "\n",
    "* The first `values` line is special; it contains the sampling points for the values that follow. These sampling points represent the *relative fractional length along the cable, starting from the proximal end and up to the distal end*, and thus may have values from $0$ to $1$.\n",
    "* If `value` is `value_multi`, one `values` line for each cell specified in the `cell list` follows,  each line with the piecewise-linear function's values at the aplready specified sampling points.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Tip\n",
    "\n",
    "This mode is targeted toward porting models written for NEURON, when values for `DENSITY` mechanism quantities are assigned over a neuron's `section` with any sort of variability.  The values instantiated on the NEURON model can be extracted with:  (where `gnabar_hh(x)` can be replaced with any other property)\n",
    "```\n",
    "access <section>; for (x) print x, <property>(x)\n",
    "```\n",
    "as seen in chapter 5 of the NEURON book, section \"Working with range variables\".\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `set synapse` statement\n",
    "\n",
    "A `set synapse` statement line is a sequence of tokens as follows:\n",
    "\n",
    "```\n",
    "set cell <projection> <synapse list> <site> <attribute> <value>\n",
    "```\n",
    "\n",
    "The tokens have the following meanings, in order:\n",
    "\n",
    "* `projection`: The name of the synaptic `<projection>` whose components` quantities are customised.\n",
    "* `synapse list`: Either a comma-separated list of `<connection>` `id`'s in strictly ascending order, or `all` to designate the whole projection.\n",
    "* `site`: either or `pre` or `post`. Since classical event-based `<projection>`s have a synaptic component only on the post-synaptic site, `post` is the only allowed site for them.\n",
    "* `attribute`: The part of the [LEMS path]( extension_paths.rst ) *within* the synaptic component, that follows after `projection[id]/post/`.\n",
    "\n",
    "Examples for `value`s are the same as with [cells]( #set-cell-statement ).\n",
    "\n",
    "When `multi`ple values are specified, one `values` line follows, with one value per mechanism instance in the specified list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `set input` statement\n",
    "\n",
    "A `set input` statement line is a sequence of tokens as follows:\n",
    "\n",
    "```\n",
    "set cell <list name> <input list> <attribute> <quantity with units>\n",
    "```\n",
    "\n",
    "The tokens have the following meanings, in order:\n",
    "\n",
    "* `projection`: The name of the `<inputList>` whose probes` quantities are customised.\n",
    "* `input list`: Either a comma-separated list of `<input>` `id`'s in strictly ascending order, or `all` to designate the whole `<inputList>`.\n",
    "* `attribute`: The part of the [LEMS path]( extension_paths.rst ) *within* the input source component, that follows after `inputlist[id]/`.\n",
    "\n",
    "Examples for `value`s are the same as with [cells]( #set-cell-statement ).\n",
    "\n",
    "When `multi`ple values are specified, one `values` line follows, with one value per mechanism instance in the specified list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment lines and inline comments\n",
    "\n",
    "In the text-based format, there may be some space between, and on, the statement lines to write comments on, to aid people (or perhaps an automated process):\n",
    "\n",
    "* *Empty lines* may be present anywhere in the text; they are ignored, but may not split other lines.\n",
    "* Within each line, the part starting from the first token that starts with a `#` character, is also ignored.\n",
    "\n",
    "<!-- XXX ensure. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting VariableRequirements\n",
    "\n",
    "Along with numerical values for regular quantities, `set` statements can also be used to assign the *targets* of [<𝚅𝚊𝚛𝚒𝚊𝚋𝚕𝚎𝚁𝚎𝚚𝚞𝚒𝚛𝚎𝚖𝚎𝚗𝚝>]( extension_pointers.ipynb )s; in fact, this is the only way for them to take a value (which they must!).  In this case, the value to specify is a [LEMS path]( extension_paths.rst ) instead of a number.  There is no need to specify units, as the model's quantities are already automatically managed by EDEN.\n",
    "\n",
    "Note: When a `VariableRequirement` set of values is interpolated over an unbranched section using [cable mode]( #Cable-mode ) with sample points, [nearest-neighbour interpolation]( https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation ) is used instead of the linear interpolation that's used for quantities. (If there is one sampling point per compartment, the effect is the same.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: A network with variability over neurons, synapses and probes\n",
    "\n",
    "To show how the above specification works, let's make a 2-D connected grid of neurons and randomise parameters throughout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; from numpy.linalg import norm; from matplotlib import pyplot as plt\n",
    "rng = np.random.default_rng(seed=43264326)\n",
    "offsets = [(1,0), (-1,1), (0,1), (1,1)] # sequential-first neighborhood\n",
    "# for bidirectional: offsets = [(x,y) for y in [-1, 0, +1] for x in [-1, +1]]+[(0,y) for y in [-1, +1]]\n",
    "\n",
    "# Make a 2D grid and then linearise it\n",
    "grid_step_size_microns = 50\n",
    "X_steps = 15; x_space = range(X_steps); X_hw = (X_steps-1)*grid_step_size_microns/2\n",
    "Y_steps = 12; y_space = range(Y_steps); Y_hw = (Y_steps-1)*grid_step_size_microns/2\n",
    "xmat, ymat = np.meshgrid(x_space, y_space, indexing='ij')\n",
    "neuron_points_steps = np.stack((xmat,ymat),axis=-1).reshape((-1,2)); neurons = len(neuron_points_steps)\n",
    "def xy_to_index(x,y): return x*Y_steps + y\n",
    "# and in spatial, not abstract coordinates\n",
    "neuron_points_microns = (np.array(neuron_points_steps) + .5 - (X_steps/2, Y_steps/2)) * grid_step_size_microns\n",
    "pts = neuron_points_microns # shorthand\n",
    "\n",
    "# Now gather the possible synapses under Neumann adjacency (ie 8-way)\n",
    "syn_list = [(xy_to_index(x,y), xy_to_index(xx,yy))  \n",
    "    for (x,y) in neuron_points_steps \n",
    "    for (dx, dy) in offsets for (xx, yy) in [(x+dx, y+dy)]\n",
    "    if 0 <= xx < X_steps and 0 <= yy < Y_steps\n",
    "]\n",
    "# Randomly flip the directions of some connections (could have both directions but it would be hard to show that)\n",
    "syn_list = np.array(syn_list)\n",
    "which_to_flip = rng.uniform(size=len(syn_list)) < 0.5\n",
    "syn_list[which_to_flip] = [(y, x) for (x,y) in syn_list[which_to_flip]]\n",
    "\n",
    "# And set up some parameters\n",
    "input_stim_idxs = np.where( 0\n",
    "    | ( norm((pts - (+3*X_hw/14,+Y_hw/2.75))/(1), axis=-1) < Y_hw*.5/2.75) \n",
    "    | ( norm((pts - (-3*X_hw/14,+Y_hw/2.75))/(1), axis=-1) < Y_hw*.5/2.75) \n",
    "    | (\n",
    "        ( norm((pts - (0,-Y_hw/2.75))/(1,.55), axis=-1) < X_hw/2)\n",
    "        & (pts[:,1] < -50)\n",
    "    ) \n",
    ")[0]\n",
    "input_stim_delay_msec = 20; input_stim_duration_msec = 200+50*rng.uniform(size=len(input_stim_idxs));\n",
    "\n",
    "neuron_Vrest_mV = ( -70 \n",
    "    + 30* (norm(pts - (0,0), axis=-1) < Y_hw*.95)\n",
    "    + 10*rng.normal(size=neurons)) \n",
    "neuron_Vrest_mV[input_stim_idxs]=-70 # Don't differentiate the \n",
    "\n",
    "syn_tau_msec = 0.1+10*rng.uniform(size=len(syn_list)); max_syn_tau_msec = np.max(syn_tau_msec)\n",
    "\n",
    "# And display\n",
    "fig, ax = plt.subplots(figsize=(16,10)); ax.set_aspect('equal')\n",
    "for idx,(i,j) in enumerate(syn_list):\n",
    "    plt.arrow(*pts[i], *pts[j]-pts[i], color=(0.9*(syn_tau_msec[idx]/max_syn_tau_msec),0,0),\n",
    "              head_width=8, width = 1,lw = 0, length_includes_head=True)\n",
    "\n",
    "plt.scatter(*neuron_points_microns[input_stim_idxs].T, color='xkcd:sky', s=225, lw=0, )\n",
    "plt.scatter(*neuron_points_microns.T, c=neuron_Vrest_mV, s=100, lw=0)\n",
    "ax.set_facecolor('#f0f4ff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a network with variability all over the place.\n",
    "\n",
    "Now let's *generate* the model file using [f-strings]( https://docs.python.org/3/reference/lexical_analysis.html#f-strings ) and [list comprehensions]( https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabline = '\\n    ' # annoyingly enough, \\ may not exist at all in a f string, not even in brackets. Fixed in Python 3.12+\n",
    "model_file = f'''\n",
    "<neuroml>\n",
    "<izhikevich2007Cell id=\"IzhCell\" v0 = \"-60mV\" C=\"100 pF\" k = \"0.7 nS_per_mV\"\n",
    "                    vr = \"-60 mV\" vt = \"-30 mV\" vpeak = \"35 mV\" \n",
    "                    a = \"0.03 per_ms\" b = \"-2 nS\" c = \"-50 mV\" d = \"100 pA\"/>\n",
    "<pulseGenerator id=\"DcProbe\" delay=\"{input_stim_delay_msec} ms\" duration=\"0 ms\" amplitude=\"0.5nA\"/>\n",
    "<expOneSynapse id=\"ExpCondSynapse\" gbase=\"8.1nS\" erev=\"20mV\" tauDecay=\"5ms\"/>\n",
    "<network id=\"Net\" type=\"networkWithTemperature\" temperature=\"37degC\" >\n",
    "\n",
    "    <population id=\"Pop\"  component=\"IzhCell\">\n",
    "    {tabline.join([ f'<instance id=\"{i}\"><location x=\"{x}\" y=\"{y}\" z=\"{0}\"/></instance>' for i, (x,y) in enumerate(pts)])}\n",
    "    </population>\n",
    "    \n",
    "    <inputList id=\"Inp\" population=\"Pop\" component=\"DcProbe\">\n",
    "    {tabline.join([ f'<inputW id=\"{i}\" target=\"Pop[{idx}]\" destination=\"synapses\" weight=\"1\"/>' for i, idx in enumerate(input_stim_idxs)])}\n",
    "    </inputList>\n",
    "\n",
    "    <projection id=\"GridProjection\" presynapticPopulation=\"Pop\" postsynapticPopulation=\"Pop\" synapse=\"ExpCondSynapse\">\n",
    "    {tabline.join([ f'<connectionWD id=\"{ii}\" preCellId=\"{pre}\" postCellId=\"{post}\" weight=\"1\" delay=\"5 ms\"/>' for ii, (pre,post) in enumerate(syn_list)])}\n",
    "    </projection>\n",
    "    \n",
    "</network>\n",
    "<Simulation id=\"MySim\" length=\"1 s\" step=\"100 us\" target=\"Net\"> <!-- no need for a seed yet, add one if you want ❗ -->\n",
    "    <OutputFile id=\"MyOutFile\" fileName=\"results.gen.txt\">\n",
    "    {tabline.join([ f'<OutputColumn id=\"v_{i}\"  quantity= \"Pop[{i}]/v\"/>' for i, _ in enumerate(pts)])}\n",
    "    </OutputFile>\n",
    "\n",
    "    <!-- Use EdenCustomSetup ❗ -->\n",
    "    <EdenCustomSetup filename=\"Example_CustomSetup.txt\"/>\n",
    "</Simulation>\n",
    "<Target component=\"MySim\"/></neuroml>\n",
    "'''\n",
    "# print(model_file)\n",
    "with open('Example_CustomSetup.nml', 'wt') as f: f.write(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the `Example_CustomSetup.txt` that goes with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_file = ''\n",
    "setup_file += 'set cell Pop all all vr multi mV\\n'\n",
    "setup_file += 'values '+ ' '.join(f'{x}' for x in neuron_Vrest_mV)+'\\n'\n",
    "\n",
    "setup_file += 'set synapse GridProjection all post tauDecay multi msec\\n'\n",
    "setup_file += 'values '+ ' '.join(f'{x}' for x in syn_tau_msec)+'\\n'\n",
    "\n",
    "setup_file += 'set input Inp all duration multi msec\\n'\n",
    "setup_file += 'values '+ ' '.join(f'{x}' for x in input_stim_duration_msec)+'\\n'\n",
    "# print(setup_file)\n",
    "with open('Example_CustomSetup.txt', 'wt') as f: f.write(setup_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eden_simulator import runEden\n",
    "results = runEden('Example_CustomSetup.nml')\n",
    "neuron_waveforms = np.array([ results[f\"Pop[{i}]/v\"] for i, _ in enumerate(pts) ])\n",
    "# plt.imshow(neuron_waveforms, interpolation='none', aspect='auto');plt.colorbar()#plt.clim((-0.07, -0.04))\n",
    "# plt.plot(neuron_waveforms[input_stim_idxs].T);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the neuron activity in pretty 4-D (surprisingly more compact than matplotlib animations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eden_simulator.display.animation import subsample_trajectories\n",
    "samples, anim_axis, sampled_time_axis, [sampled_soma_voltage] = subsample_trajectories(\n",
    "    results['t'], [neuron_waveforms.T * 1000], animation_speed=0.0096, animation_frames_per_second=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q k3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k3d; from eden_simulator.display.spatial.k3d import Plot\n",
    "points_plot = plot = Plot(background_color=0xf0f4ff, camera_auto_fit=False) # to override camera orientation\n",
    "\n",
    "k3d_anim_dict = { str(real_time): x.astype(np.float32) \n",
    "                for (real_time, x) in zip(anim_axis, sampled_soma_voltage)  }\n",
    "k3d_label_dict = { str(real): f't = {sim:.3f} ~ s' for (real, sim) in zip(anim_axis, sampled_time_axis)  }\n",
    "plt_points = k3d.points(positions=np.c_[pts,[0]*len(pts)].astype(np.float32),attribute=k3d_anim_dict,\n",
    "        color_range=[-80, -20],point_size=30,color_map=k3d.matplotlib_color_maps.Hot); plot += plt_points\n",
    "\n",
    "plot.camera = plot.get_auto_camera(pitch=30, yaw=10)[:6]+[0,1,0] # set 'y' to up ! vecs are pos, tgt, up\n",
    "plt_label = k3d.text2d(k3d_label_dict, (0.,0.), label_box=False); plot += plt_label # add 2d elements AFTER setting auto camera\n",
    "plot.fps = 48;\n",
    "from IPython.display import display, HTML, IFrame\n",
    "plot.snapshot_type = 'inline'; display(HTML(plot.get_snapshot()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/latex"
   },
   "source": [
    "% LATER automate, size 60 or 90\n",
    "\\begin{center}\\sphinxincludegraphics[width=0.9\\textwidth]{{_static/extension_customsetup_balls}.png}\\end{center}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this a very simple network, and its behaviour is quite sensitive to the parameter values.  Since it lacks inhibitory synapses, the balance between full and absent firing is roughly the balance between:\n",
    "\n",
    "> ( $I_{syn}$ *times* $\\tau_{syn}$ times synaptic out-degree ) versus ( $I_{leak}$ *times* synaptic delay )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More examples\n",
    "\n",
    "As explained [above]( #set-cell-statement ), setting parameters over the extent of spatially-detailed cells can slightly more involved.  This is shown in a follow-up [ example ]( example_spatial_customsetup.ipynb ).\n",
    "\n",
    "The usage of `set` statements for `<VariableReference>`s is shown in the [\\<𝙴𝚍𝚎𝚗𝚃𝚒𝚖𝚎𝚜𝚎𝚛𝚒𝚎𝚜𝚁𝚎𝚊𝚍𝚎𝚛\\> example]( extension_io.ipynb#Example:-An-arbitrary-pulse-current-probe ).\n",
    "\n",
    "<!-- NEXT the planar technique. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "Now as the last thing, we'll fetch a screenshot to use in the documentation's [example gallery]( https://eden-simulator.org/gallery.html ).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "plot = points_plot\n",
    "plot.grid_visible = False\n",
    "plot.screenshot_scale = 1\n",
    "plot.axes_helper = 0\n",
    "plot.colorbar_object_id = 0 # Disabling colorLegend programmatically\n",
    "# plt_points.color_range = [-1, +1]\n",
    "# plt_points.point_size = 15\n",
    "plt_label.visible=False\n",
    "plot -= plt_label\n",
    "plot.background_color = 0xffffff\n",
    "data_timestep = np.diff(results['t'])[0] # assuming fixed timestep\n",
    "traj_samples_per_frame = round((0.0096/48)/data_timestep)\n",
    "print(len(list(k3d_anim_dict.keys())))\n",
    "framets = [y[x] for y in [list(k3d_anim_dict.keys())] for x in range(int(0.037/(data_timestep*traj_samples_per_frame)),int(0.037/(data_timestep*traj_samples_per_frame))+1,traj_samples_per_frame)]\n",
    "# 3.8663\n",
    "# for frame,sample in enumerate(sample_for_frame):print(sample_for_frame)\n",
    "# print(framets)\n",
    "frames = []\n",
    "import time\n",
    "try:\n",
    "    from k3d.headless import k3d_remote, get_headless_driver\n",
    "    headless = k3d_remote(plot, get_headless_driver(), width=500, height=500)\n",
    "    # plot.camera = lotp.get_auto_camera(pitch=30, yaw=10)[:6]+[0,1,0] # set 'y' to up !  LATER zoom a bit also; vecs are pos, tgt, up\n",
    "    plot.camera = [0, 0, +200, 0,0,0, 0,1,0]\n",
    "    headless.sync(hold_until_refreshed=True)\n",
    "    headless.camera_reset(.8)\n",
    "\n",
    "    # Set each attribute because does headless not like dicts ...\n",
    "    for frame,real_time in enumerate(framets):\n",
    "        # need to clear before reassigning...\n",
    "        for x in plt_points: x.attribute = {k:[] for k,v in x.attribute.items()}\n",
    "        \n",
    "        plt_points.attribute = k3d_anim_dict[str(real_time)]\n",
    "        print(real_time)\n",
    "        headless.sync()\n",
    "        time_start = time.time()\n",
    "        screenhot = headless.get_screenshot()\n",
    "        time_end = time.time()\n",
    "        # print(f\"{time_end - time_start} sec\")\n",
    "        frames.append(screenhot)\n",
    "finally:\n",
    "    headless.close()\n",
    "import IPython\n",
    "IPython.display.Image(data=frames[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL\n",
    "import io\n",
    "\n",
    "# Stage 1: Crop\n",
    "frame_data = [ Image.open(io.BytesIO(x)) for x in frames]\n",
    "frame_data = [ x.crop((int(.0*x.size[0]), int(.1*x.size[1]), int((1-.0)*x.size[0]), int((1-.1)*x.size[1]))) for x in frame_data ]\n",
    "# frame_data = [ x.crop((int(0.25*x.size[0]), int(0.25*x.size[1]), x.size[0], x.size[1])) for x in frame_data ]\n",
    "\n",
    "# Stage 2: Resize\n",
    "for x in frame_data: x.thumbnail((240,200))\n",
    "    \n",
    "# Stage 3: Lossy - or not\n",
    "# to apng, or gif\n",
    "outbuf = io.BytesIO()\n",
    "frame_data[0].save(outbuf, format='gif', save_all=True, append_images=frame_data[1:], duration=100, loop=0)\n",
    "print('GIF size:',len(outbuf.getvalue()))\n",
    "\n",
    "# to alpha channel out - how is this not compressed already\n",
    "im = Image.open(outbuf)\n",
    "# https://github.com/python-pillow/Pillow/issues/3292#issuecomment-410837926\n",
    "newframes = [x.copy().convert('RGB') for x in PIL.ImageSequence.Iterator(im)]\n",
    "\n",
    "aabuf = io.BytesIO()\n",
    "newframes[0].save(aabuf, format='png', save_all=True, append_images=newframes[1:], duration=100, loop=0)\n",
    "print(len(aabuf.getvalue()))\n",
    "\n",
    "# to lossless recompression\n",
    "import oxipng\n",
    "oxipng_opts = {'level':6}\n",
    "aa = oxipng.optimize_from_memory(aabuf.getvalue(), **oxipng_opts)\n",
    "print('Optimized PNG size:',len(aa))\n",
    "\n",
    "# display(IPython.display.Image(data=outbuf.getvalue()))\n",
    "# display(IPython.display.Image(data=aabuf.getvalue()))\n",
    "display(IPython.display.Image(data=aa))\n",
    "\n",
    "# IPython refuses to nbconvert gif files, and apng is not as efficient, we'll have to get creative ...\n",
    "# Accept having a png file for now? nah it's twice as big as the gif after gif compression.\n",
    "# and save the file under an explicit name bc nbsphinx is misbehaving\n",
    "with open('_static/thumb_extension_customsetup.png','wb') as f: f.write(aa)\n",
    "# with open('_static/thumb_tut_net.gif','wb') as f: f.write(outbuf.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "And minimize plots for publishing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "from eden_simulator.display.spatial.k3d import MinimizePlot\n",
    "for x in [points_plot]: MinimizePlot(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
